# Cloud_3 â€“ Processamento de â€œTomadosâ€

Automatiza a etapa de pÃ³s-triagem (â€œCloud_3â€) a partir das notificaÃ§Ãµes de â€œTOMADOSâ€ geradas pelo Cloud_2.  
Recebe mensagens no Pub/Sub, extrai campos de PDFs via Document AI, gera linhas de CSV e arquivos de tomadores, e faz upload dos resultados para o GCS.

---

## ğŸ“‚ Estrutura do Projeto

```

Cloud\_3/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py            # Carrega variÃ¡veis do .env e validaÃ§Ãµes bÃ¡sicas
â”œâ”€â”€ db/
â”‚   â””â”€â”€ triage\_consulta.py     # Leitura/atualizaÃ§Ã£o de tomados\_status no SQLite
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ acumuladores.py        # DicionÃ¡rio cÃ³digoâ†’valor de acumuladores
â”‚   â”œâ”€â”€ consulta\_for.py        # Consulta CNPJ na API ReceitaWS
â”‚   â”œâ”€â”€ document\_ai.py         # Wrapper genÃ©rico para Document AI
â”‚   â”œâ”€â”€ tratamentos.py         # Limpeza de strings (CNPJ, datas, valores...)
â”‚   â”œâ”€â”€ tratamentos\_csv.py     # Pipeline de CSV e split de tomadores
â”‚   â””â”€â”€ gcs\_upload.py          # FunÃ§Ã£o para upload em GCS (nÃ£o mostrado aqui)
â”‚ 
â”œâ”€â”€ cloud3_subscriber.py       # Subscriber Pub/Sub que dispara o processamento
â”œâ”€â”€ processa_tomados.py        # LÃ³gica principal para extrair, gerar e enviar resultados
â”œâ”€â”€ logs/                      # Arquivos de log gerados em runtime
â”œâ”€â”€ heartbeat.json             # Atualizado por worker/subscriber para monitoramento
â”œâ”€â”€ triage\_status.db           # SQLite de status de triagem (tomados\_status)
â”œâ”€â”€ .env                       # VariÃ¡veis de ambiente (credentials, paths, IDs)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                  # Esta documentaÃ§Ã£o

````

---

## âš™ï¸ PrÃ©-requisitos

- **Python 3.9+**  
- Conta de serviÃ§o GCP com permissÃµes para:
  - Document AI  
  - Pub/Sub (assinatura)  
  - Cloud Storage (upload de arquivos)  
- **SQLite** (jÃ¡ utilizado via `sqlite3` no script)  
- Acesso pÃºblico ou credenciado Ã  API ReceitaWS (receitaws.com.br)  

---

## ğŸ”§ ConfiguraÃ§Ã£o

1. **Crie um arquivo `.env` na raiz** com as variÃ¡veis abaixo:

   ```ini
   # SQLite de status de triagem
   TRIAGE_DB_PATH=/caminho/para/triage_status.db

   # Pasta de entrada (pastas â€œID-APELIDOâ€ com subpasta TOMADOS/)
   SEPARADOS_DIR=/caminho/para/separados

   # Google Cloud Project e Document AI
   GCLOUD_PROJECT_ID=meu-project-id
   GCLOUD_LOCATION=us
   GCLOUD_PROCESSOR_ID=meu-processor-id
   GCLOUD_PROCESSOR_VERSION_ID=meu-processor-version

   # Credenciais ADC
   GOOGLE_APPLICATION_CREDENTIALS=/caminho/para/service-account.json

   # MIME type esperado (geralmente application/pdf)
   GCLOUD_MIME_TYPE=application/pdf

   # GCS para resultados â€œtomadosâ€
   GCS_BUCKET_TOMADOS=meu-bucket
   GCS_PREFIX_RESULTADOS=tomados_saida

   # PÃ¡ginas a extrair (ex.: "1,2,3")
   PAGE_SELECTOR=1

   # Segundos de espera entre chamadas Document AI (evita quotas)
   TEMPO_ESPERA=16

   # Pub/Sub
   PROJECT_ID=meu-project-id       # opcional, usa GCLOUD_PROJECT_ID por padrÃ£o
   SUBSCRIPTION_ID=cloud3-tomados-sub
````

2. **NÃ£o versionar** o `.env` nem o JSON de credenciais (jÃ¡ incluÃ­dos em `.gitignore`).

---

## ğŸš€ InstalaÃ§Ã£o

```bash
git clone https://seu-repo/Cloud_3.git
cd Cloud_3
python -m venv .venv
source .venv/bin/activate       # Linux/macOS
.venv\Scripts\activate          # Windows
pip install -r requirements.txt # inclua google-cloud-documentai, google-cloud-pubsub, pandas, requests...
```

---

## â–¶ï¸ Uso

### 1. Subscriber Pub/Sub

Fica escutando mensagens e dispara o processamento:

```bash
python -m scripts.cloud3_subscriber
```

* Conecta Ã  assinatura `PROJECT_ID/SUBSCRIPTION_ID`.
* Callback puxa `os_id` e `pasta`, verifica status, chama `processar_os_pubsub()`.

### 2. Processamento Batch (loop principal)

Pode-se rodar em modo polling (sem Pub/Sub):

```bash
python -m scripts.processa_tomados
```

* Varre `triage_status.db` por `tomados_status = 'Pendente'`.
* Para cada OS:

  1. LÃª todos os PDFs em `SEPARADOS_DIR/<ID-APELIDO>/TOMADOS/`
  2. Processa cada PDF com Document AI
  3. Aplica padrÃµes (CNPJ, datas, cÃ³digos de serviÃ§o, CSRF, acumuladoresâ€¦)
  4. Gera CSV e arquivos de tomadores via `tratamentos_csv.exe()`
  5. Renomeia PDFs originais e atualiza `GERAL.txt`
  6. Envia `GERAL.txt` e arquivos de tomadores para GCS
  7. Atualiza `tomados_status = 'ConcluÃ­do'` em triage\_status.db

---

## ğŸ› ï¸ Monitoramento e Logs

* **Logs**: em `logs/`, um arquivo `tomados.log` (configurado pelo `logging.basicConfig`).
* **Heartbeat**: `heartbeat.json` no diretÃ³rio de scripts, com a Ãºltima mensagem e timestamp:

  ```json
  { "ts": "2025-07-17T15:23:00Z", "msg": "empresa 12345-CLIENTE" }
  ```

  Use em health checks ou dashboards.

---

## ğŸ”„ ContribuiÃ§Ã£o

1. Fork do repositÃ³rio
2. Nova branch (`git checkout -b feature/xyz`)
3. Commits atÃ´micos e claros
4. Pull Request para revisÃ£o

---

## ğŸ¤ LicenÃ§a

MIT Â© Renata BopprÃ© Scharf

```
```
